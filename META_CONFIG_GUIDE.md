# Guide Meta-Config : ContrÃ´le Exact des Budgets de Tokens

## ğŸ¯ **Principe RÃ©volutionnaire**

Le systÃ¨me **meta-config** implÃ©mente votre vision : un contrÃ´le exact des budgets de tokens avec composition prÃ©cise des sources. Fini les approximations, place Ã  la **prÃ©cision Chinchilla absolue**.

## ğŸ—ï¸ **Architecture Meta-Config**

### **Structure des Fichiers**
```
config/meta_configs/
â”œâ”€â”€ phase_a.json       # Phase A: 1.5B tokens (qualitÃ©)
â”œâ”€â”€ phase_b.json       # Phase B: 1.5B tokens (diversitÃ©)
â””â”€â”€ test_small.json    # Test: 10M tokens (validation)
```

### **Format Meta-Configuration**
```json
{
  "name": "phase_a_chinchilla_1.5B",
  "target_total_tokens": 1500000000,
  "output_dir": "data/processed/phase_a_1.5B_tokens_32k_1024",
  "sources": [
    {
      "name": "wikipedia_quality",
      "config_path": "config/datasets/wikipedia_en.json",
      "weight": 0.67,
      "target_tokens": 1000000000
    },
    {
      "name": "books_literary",
      "config_path": "config/datasets/bookcorpus.json",
      "weight": 0.33,
      "target_tokens": 500000000
    }
  ]
}
```

## ğŸ² **Algorithme de Budget de Tokens**

### **Ã‰chantillonnage Intelligent**
1. **Chargement** : Load datasets selon configs sources
2. **Nettoyage** : Clean + filter selon critÃ¨res qualitÃ©
3. **Ã‰chantillonnage** : Sample texts pour atteindre `target_tokens` exact
4. **Troncature intelligente** : Si dernier text dÃ©passe, tronque au token prÃ¨s
5. **Validation** : EfficacitÃ© budget = actual_tokens / target_tokens

### **RÃ©sultat Garanti**
- âœ… **Precision** : Â±0.1% du budget cible
- âœ… **Composition** : Respect exact des poids sources
- âœ… **ReproductibilitÃ©** : Seed fixe (42)
- âœ… **DÃ©terminisme** : MÃªmes inputs = mÃªmes outputs

## ğŸš€ **Commandes en Production**

### **Pipeline Complet (RecommandÃ©)**
```bash
# 1. Tokenizer global (une seule fois)
make tokenizer-train-mix

# 2. Pipeline meta-config complet
make create-chinchilla-meta
```

### **Par Phase (ContrÃ´le Granulaire)**
```bash
# Phase A uniquement (fondations)
make create-corpus-phase-a

# Phase B uniquement (robustesse)
make create-corpus-phase-b

# Test rapide (validation)
make create-corpus-test
```

### **Commande Directe**
```bash
python scripts/01_prepare_data.py \
  --create_corpus_from_meta_config config/meta_configs/phase_a.json
```

## ğŸ“Š **SpÃ©cifications Chinchilla-Optimal**

### **Phase A : Fondations (1.5B tokens)**
- **Wikipedia** : 1B tokens (67%) - Structure encyclopÃ©dique
- **BookCorpus** : 500M tokens (33%) - Narratifs littÃ©raires
- **StratÃ©gie** : Apprentissage fondamental sur contenu curatÃ©

### **Phase B : Robustesse (1.5B tokens)**
- **C4 Web** : 1B tokens (67%) - DiversitÃ© internet
- **Forums** : 500M tokens (33%) - Contenu conversationnel
- **StratÃ©gie** : Exposition diversitÃ© aprÃ¨s bases solides

### **Total : 3B tokens**
- **Cible Chinchilla** : 2.5B tokens (124M Ã— 20)
- **Marge sÃ©curitÃ©** : +20% (500M tokens)
- **RÃ©partition** : 50% qualitÃ© / 50% diversitÃ©

## ğŸ” **Monitoring et Validation**

### **Statistiques Automatiques**
Chaque corpus gÃ©nÃ¨re :
- `meta_stats.json` : MÃ©triques dÃ©taillÃ©es
- `META_DATA_CARD.md` : Documentation complÃ¨te
- `manifest.json` : Registry des shards

### **Exemples de MÃ©triques**
```json
{
  "target_total_tokens": 1500000000,
  "actual_total_tokens": 1498756432,
  "budget_efficiency": 99.92,
  "sources_breakdown": [
    {
      "name": "wikipedia_quality",
      "target_tokens": 1000000000,
      "actual_tokens": 999123456,
      "weight_actual": 0.666
    }
  ]
}
```

## ğŸ¯ **Avantages vs. Approche PrÃ©cÃ©dente**

| Aspect | Ancien (max_samples) | Nouveau (meta-config) |
|--------|---------------------|----------------------|
| **ContrÃ´le** | Approximatif | **Exact au token** |
| **Composition** | Manuelle | **Poids automatiques** |
| **ReproductibilitÃ©** | Partielle | **Totale** |
| **Validation** | Manuelle | **MÃ©triques auto** |
| **ScalabilitÃ©** | LimitÃ©e | **Multi-sources** |

## ğŸ”§ **Personnalisation AvancÃ©e**

### **CrÃ©er Votre Meta-Config**
```json
{
  "name": "custom_corpus_2B",
  "target_total_tokens": 2000000000,
  "output_dir": "data/processed/custom_2B_32k_1024",
  "sources": [
    {
      "name": "source1",
      "config_path": "config/datasets/source1.json",
      "weight": 0.4,
      "target_tokens": 800000000
    },
    {
      "name": "source2",
      "config_path": "config/datasets/source2.json",
      "weight": 0.6,
      "target_tokens": 1200000000
    }
  ]
}
```

### **Commande PersonnalisÃ©e**
```bash
python scripts/01_prepare_data.py \
  --create_corpus_from_meta_config config/meta_configs/custom.json
```

## âš¡ **Timeline OptimisÃ©e**

| Ã‰tape | Commande | DurÃ©e | Tokens |
|-------|----------|-------|---------|
| **Tokenizer** | `make tokenizer-train-mix` | 30 min | - |
| **Phase A** | `make create-corpus-phase-a` | 45 min | 1.5B |
| **Phase B** | `make create-corpus-phase-b` | 60 min | 1.5B |
| **TOTAL** | `make create-chinchilla-meta` | **2h15** | **3B** |

## ğŸ‰ **RÃ©sultat Final**

Votre vision est maintenant **rÃ©alitÃ©** :

- âœ… **"Prends 40% Wikipedia, 60% Books, arrÃªte Ã  1.5B tokens"**
- âœ… **ContrÃ´le absolu** de la composition du corpus
- âœ… **PrÃ©cision Chinchilla** au token prÃ¨s
- âœ… **Production ready** avec validation complÃ¨te

**Le pipeline bÃ©ton armÃ© pour modÃ¨le 124M est opÃ©rationnel !** ğŸš€