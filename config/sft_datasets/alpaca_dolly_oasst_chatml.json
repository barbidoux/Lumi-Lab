{
  "name": "alpaca_dolly_oasst_chatml",
  "description": "High-quality multi-dataset SFT corpus: Alpaca + Dolly + OASST1 with ChatML formatting",
  "version": "1.0",
  "template": "chatml",

  "output_params": {
    "sequence_length": 1024,
    "shard_size": 2000,
    "train_ratio": 0.95
  },

  "quality_filters": {
    "min_prompt_length": 10,
    "max_prompt_length": 2000,
    "min_response_length": 15,
    "max_response_length": 2000,
    "filter_urls": true,
    "filter_code_blocks": false,
    "require_ascii": false
  },

  "datasets": [
    {
      "name": "alpaca_gpt4",
      "type": "huggingface",
      "dataset_name": "tatsu-lab/alpaca",
      "subset": null,
      "split": "train",
      "streaming": false,
      "max_samples": 50000,
      "text_fields": {
        "prompt": "instruction",
        "response": "output"
      },
      "weight": 0.4,
      "description": "Stanford Alpaca - High-quality instruction-following dataset"
    },
    {
      "name": "dolly_v2",
      "type": "huggingface",
      "dataset_name": "databricks/databricks-dolly-15k",
      "subset": null,
      "split": "train",
      "streaming": false,
      "max_samples": 15000,
      "text_fields": {
        "prompt": "instruction",
        "response": "response"
      },
      "weight": 0.3,
      "description": "Databricks Dolly v2 - Human-generated instruction/response pairs"
    },
    {
      "name": "openassistant_v1",
      "type": "huggingface",
      "dataset_name": "OpenAssistant/oasst1",
      "subset": null,
      "split": "train",
      "streaming": false,
      "max_samples": 30000,
      "text_fields": {
        "prompt": "text",
        "response": "text"
      },
      "weight": 0.3,
      "description": "OpenAssistant OASST1 - High-quality conversational data with human preferences",
      "custom_processing": {
        "conversation_tree": true,
        "filter_language": "en",
        "min_score": 2,
        "role_filter": ["prompter", "assistant"]
      }
    }
  ],

  "processing_metadata": {
    "target_conversations": 75000,
    "estimated_tokens": 40000000,
    "processing_time_estimate": "60-90 minutes",
    "quality_focus": "instruction_following_and_conversation",
    "template_rationale": "ChatML chosen for explicit role separation and multi-turn capability"
  }
}