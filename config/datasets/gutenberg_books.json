{
  "input_path": "sedthh/gutenberg_english",
  "output_dir": "data/processed/gutenberg_books_32k_1024",
  "tokenizer_path": "data/tokenizer/spm32k",
  "vocab_size": 32768,
  "sequence_length": 1024,
  "min_length": 200,
  "max_length": 12000,
  "use_minhash": true,
  "minhash_threshold": 0.85,
  "train_ratio": 0.98,
  "shard_tokens": 2000000,
  "train_tokenizer": false,
  "use_streaming": true,
  "max_stream_samples": 60000,
  "max_samples": 50000,
  "_comment": "Project Gutenberg English books dataset - classic literature in public domain. Perfect for high-quality narrative content. Max ~60k books available, using streaming for efficient processing."
}