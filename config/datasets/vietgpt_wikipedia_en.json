{
  "input_path": "vietgpt/wikipedia_en",
  "output_dir": "data/processed/vietgpt_wikipedia_en_32k_1024",
  "tokenizer_path": "data/tokenizer/spm32k",
  "vocab_size": 32768,
  "sequence_length": 1024,
  "min_length": 100,
  "max_length": 8000,
  "use_minhash": true,
  "minhash_threshold": 0.85,
  "train_ratio": 0.98,
  "shard_tokens": 4000000,
  "train_tokenizer": false,
  "use_streaming": true,
  "max_stream_samples": 8000000,
  "max_samples": 3000000,
  "_comment": "VietGPT Wikipedia EN dataset - comprehensive Wikipedia articles with potentially better preprocessing than standard Wikipedia dumps. High-quality encyclopedic content."
}