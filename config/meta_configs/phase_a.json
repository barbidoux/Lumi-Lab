{
  "name": "phase_a_chinchilla_1.5B",
  "description": "Phase A: High-quality foundation corpus for curriculum learning",
  "output_dir": "data/processed/phase_a_1.5B_tokens_32k_1024",
  "target_total_tokens": 1500000000,
  "tokenizer_path": "data/tokenizer/spm32k",
  "vocab_size": 32768,
  "sequence_length": 1024,
  "train_ratio": 0.98,
  "shard_tokens": 2000000,
  "use_minhash": true,
  "minhash_threshold": 0.85,
  "sources": [
    {
      "name": "vietgpt_wikipedia",
      "config_path": "config/datasets/vietgpt_wikipedia_en.json",
      "weight": 0.67,
      "target_tokens": 1000000000,
      "description": "VietGPT Wikipedia EN - comprehensive Wikipedia with enhanced preprocessing"
    },
    {
      "name": "books_literary",
      "config_path": "config/datasets/gutenberg_books.json",
      "weight": 0.33,
      "target_tokens": 500000000,
      "description": "Project Gutenberg - classic literature and narrative structures for literary understanding"
    }
  ],
  "_phase": "A",
  "_model_target": "124M parameters",
  "_strategy": "Curriculum learning foundation with high-quality, structured content",
  "_comment": "Phase A focuses on teaching the model fundamental language patterns from curated, high-quality sources before exposure to noisy web data."
}